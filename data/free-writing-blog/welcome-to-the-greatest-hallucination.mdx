---
title: 'Welcome to the Greatest Hallucination'
date: '2025-11-20'
tags: ['philosophy', 'ai', 'tech-industry', 'baudrillard']
draft: false
images: ['/static/images/free-writing-images/welcome-to-the-greatest-hallucination/simulacra.png']
summary: "We're not in a bubble—bubbles pop and you return to normal. We're in a simulacrum. There's no normal to return to. A Baudrillardian analysis of the AI industry's drift from reality into hyperreality, and how to survive the inevitable reload."
project: philosophy
---

![From Code to Cult: The AI Simulation Machine](/static/images/free-writing-images/welcome-to-the-greatest-hallucination/simulacra.png)

# Welcome to the Greatest Hallucination

Wake up in the morning, brush your teeth and open LinkedIn, tell me what do you see?

A stream of "groundbreaking" announcements, mind-blowing achievements. "Experts" who are absolutely "thrilled to share" their latest success. Apparently, we live in a world where everyone is a visionary, every startup is a unicorn, stocks are rising, the market is booming. Life is good!

But here's the thing: it's all of them but you.

You scroll faster. Everyone's climbing the promotion ladder, making money, building products. And you? You're drowning. Linear algebra, optimization, ML and deep learning, then LLMs and agent systems, MLOps and system design. Too much on your plate. Too many papers to keep up with. Too many people to catch up to.

You know what success looks like: the very smart guy who writes complex math in papers, crafts dense appendices with Greek letters. Designs architecture diagrams that look like circuit boards. We've learned to recognize this shape. We see it and think: this must be real. Look how cool and useful it is! Well, let me ask you—are you sure that's what success looks like? How could you be sure?

I know it's not an easy question, because you didn't live that success to be really sure about it, so let me help you. Let me take you to IKEA.

---

## The IKEA Problem

You walk through showrooms—staged rooms no one lives in. You think, *look how cool*, then go home and arrange your real apartment to match. The fake is not a photoshopped image of what real rooms are. It *becomes the template* for what real rooms are. The fake produces the reality.

Hold that thought. It's about to explain the entire AI industry.

That inversion—where the image stops imitating reality and reality starts imitating the image—creates a self-inflating balloon. It keeps you up at night trying to catch a career that doesn't exist. And it's not only you. You suffer, companies suffer, and even the whole economy. But wait, I am not saying we are in a bubble. Bubbles pop and you return to normal. We're in something worse—a **simulacrum**. There is no normal to return to.

Baudrillard, the famous postmodern philosopher, explained how reality can shift through stages until you arrive at a complete fake with no ground to stand on—a stage he called simulacrum. He left us with this warning:

> *"The simulacrum is never that which conceals the truth—it is the truth which conceals that there is none. The simulacrum is true!"*

That's a dangerous idea. And if you buy it, we'll need to talk about it. But first, let me tell you how we got here.

---

## From Showroom to Simulacrum

Going from reality to simulation is not new. From the deep past, people gathered food and built houses. When problems happened, they returned to the wise guys who helped them resolve things. The wise guys became important, changed the narrative—created dogmas or religions—and people lived by that. The hallucination became something real. Not false info; the code that all people live by.

The simulation validates and amplifies itself. It rewards narrators, not value builders. It's not the farmers or workers who came to power, but the priests and kings. It's not the workers who make money, but the guys who run the bank. The showroom always wins.

But who cares about the past? We are in the AI age now—the culmination of the simulation. And it didn't take us centuries to get here. This age was really fast. Just within 15 years we went from something real to full simulacrum.

### Stage 1: The Sign Reflects Reality (2008–2012)

ML became hot because ML was genuinely useful. Andrew Ng's course goes viral—100,000 students learn machine learning. AlexNet crushes ImageNet in 2012. Code is public. Claims are testable. Results are reproducible. Knowledge leads to results. Results lead to reward.

This is the IKEA catalogue *before* the inversion. The picture still represents a real room. You see ML working. You learn ML. You build things that work. Simple.

Then the break: too many ML graduates, too much venture capital. Everyone needs a new story.

### Stage 2: The Sign Distorts Reality (2013–2023)

Now the showrooms start getting fancier than any real apartment.

Ten years of gradual hype buildup. DeepMind's DQN masters Atari games. AlphaGo beats Lee Sedol and the world loses its mind. Real breakthroughs—but the hype machine kicks in. "Deep Learning" replaces "neural networks"—same math, better branding. Papers test 47 architectures, report only the winner. Every startup adds "AI-powered" to their deck.

Elon promises full self-driving, every year. IBM Watson beats Jeopardy, then promises to cure cancer. Self-driving is "99% solved"—except the last 1% is the entire problem. GPT-2 is "too dangerous to release"—for nine months, as marketing. GPT-3 costs $12M to train and nobody can reproduce it.

The best CS paper in a decade—a double greedy algorithm, pure computer science—gets published at an ML conference. Because that's where the attention is. That's where the funding is. The narrative captures even the fields it has nothing to do with.

The sign still points to *something*. Just not as much as claimed. You can still live in the apartment—it just doesn't look quite like the showroom.

### Stage 3: The Sign Masks Absence (2023–2024)

November 2022: ChatGPT launches. Within two months, 100 million users. AI stops being a niche topic and becomes the only topic.

The multi-billion rounds begin. Microsoft puts $13B into OpenAI. Google puts $3B+ into Anthropic. Amazon puts $8B into Anthropic.

What are they buying? Not current capabilities—those are commoditizing. They're buying territory in the AGI market. The market that doesn't exist yet. The market everyone agrees will exist because everyone is buying territory in it.

This is when you stop arranging your apartment to look like IKEA and start *living in* IKEA. The showroom isn't distorting reality anymore—it's replacing it.

### Stage 4: Full Simulacrum (2025–Present)

Now the showroom generates its own reality. Nobody even remembers what a real apartment looks like.

**The simulation protects its narrators.** November 2023—OpenAI's board fires Sam Altman. 700 employees threaten to quit. Microsoft offers to hire everyone. Sam returns in five days. The board is replaced. The best narrator overpowers the value builders (the chief scientist and the board).

**The simulation captures legitimacy.** October 2024—Hinton and Hopfield win the Nobel Prize in Physics. Hassabis and Jumper win the Chemistry Nobel for AlphaFold. Now, Boltzmann machines and Hopfield networks are genuinely important work—but the Nobel Committee doesn't typically award Physics prizes for statistical modeling of memory. The prize registered narrative weight as much as scientific contribution. The ultimate gatekeepers of legitimacy validated the simulation.

**The simulation scales beyond reason.** January 2025—Stargate project announces $500B for AI infrastructure. Half a trillion dollars. The number is so absurd it glitches. But a number that large *must* mean something real is happening. The scale proves the substance. Which justifies more investment. Which proves AGI is near.

**It's turtles all the way down.** Nvidia's trillion-dollar valuation isn't based on chips sold. It's based on AI expectations. Those expectations are based on OpenAI's valuation. OpenAI's valuation is based on Microsoft's investment. Microsoft's investment is based on Azure compute growth. Azure compute growth is based on... startups buying compute with VC money to build AI products whose valuations are based on Nvidia's stock price.

No original. No ground truth. Just expectations inflating expectations. The showroom has replaced the city. The simulation bootstraps its own reality.

---

## The Trap

Before you go looking for the architect—some shadowy cabal pulling strings—let me save you time: there aren't any. Nobody designed this. The Matrix wasn't built by machines. It emerged from us.

Fear of exclusion. Need for status. Pattern-matching for safety. These instincts kept us alive in the stone age. Now they drive us to chase metrics we don't believe in, signal belonging to tribes we don't respect.

The system optimizes for its own metrics—valuations, engagement, citations—which drift further and further from anything that matters. Big Tech Giant invests $500 million into hot AI startup. Condition: startup must spend it buying cloud credits back from Big Tech Giant. Tech Giant records it as "Cloud Revenue." Startup records it as "Valuation." Everyone's stock goes up. No customer bought a product. No money left the ecosystem.

The market values **Sign Value**—hype, prestige, the appearance of innovation—over **Use Value**—does this solve a boring problem profitably? That gap is where the system eats itself.

And here's the trap: awareness doesn't help. Workers see through the hype but stay—trapped by hope ("If I build good tech, I'll succeed"), belief ("We really are building AGI"), and golden handcuffs (equity vesting, resume building, sunk cost). Narrators see through it too—trapped by competition (other narrators will out-simulate you) and lock-in (admitting simulation destroys valuation).

You know the glitches. You feel them. We still die from cancer. We still live in small apartments. We still sit in traffic. A relatively simple pandemic like COVID pushed us to the limit. Tell me again how AI is changing the world?

Valuations go up but customers don't exist. "Experts" multiply but problems don't get solved. Revenue grows but it's recycled VC money. Everyone is "thriving" but everyone is burned out. Productivity tools proliferate but nobody has more time. The most valuable companies sell picks and shovels for a gold rush that may never come.

The narrative says revolution. Reality says: same problems, shinier dashboards.

And here's the really fucked up part: we see all of this. We scroll past "thrilled to share" with a smirk. We joke about the grifters. We roll our eyes at the complexity theater. And we keep playing. We refresh portfolios. We network at conferences. We update LinkedIn with carefully crafted humility. We half-hope our company gets acquired before anyone checks whether the metrics are real.

Cynical distance is how we tolerate our participation. We know it's bullshit. We do it anyway. The performance continues because everyone is performing, and no one wants to be the first to stop.

---

## The Inevitable Collision

So we like the game—why should we care? Couldn't the simulation run forever?

No. IKEA showrooms need someone to pay the electricity bill. Simulations need fuel. And the fuel is running out from three directions at once.

### The Ceiling

The AI boom was driven by economic incentive. Big Tech drove AI from a few percentage points of market cap to 45%. That's an order of magnitude growth. Incredible. But here's the math problem: to double again, either the entire economy doubles, or AI sucks all the money from physical reality—real estate, healthcare, logistics, food. Both are practically impossible.

The market cap ceiling is real. When investors realize the growth story has hit its structural limit, funding stops. When funding stops, the simulation loses its fuel.

### The Paradox

AI promises automation and cost savings. Translation: massive job displacement. The pitch deck says "efficiency." The spreadsheet says "layoffs."

But automation erodes the customer base. If AI replaces workers, who pays for AI products? Who buys the SaaS subscriptions? Who upgrades to premium? The product destroys its own market. This isn't a distant theoretical concern—it's the structural logic of every AI business plan that promises cost savings through headcount reduction. Each successful deployment shrinks the pool of people who can afford to be customers.

You can't automate your way to prosperity if prosperity requires customers with jobs. Henry Ford understood this a century ago when he raised wages so his workers could buy his cars. The AI industry is running Ford's logic in reverse.

### The Wall

Tons of papers. Tons of conferences. Tons of PhDs. But where are the breakthroughs?

It feels like technology building, not research. Same architectures, more parameters, bigger datasets. The spectacular gains that launched the hype—GPT-2 to GPT-3, GPT-3 to GPT-4—are flattening. The exponential narrative meets logarithmic reality. We hit the wall. We just haven't admitted it yet.

### The Collision

Every simulation eventually collides with something it can't simulate. The AI simulation will collide with economics (the ceiling), society (the paradox), and science (the wall).

When it does—and it will—the question isn't *whether* there's a correction. It's how severe.

When the simulation breaks, the hype vanishes. But the value stays. The infrastructure stays. Electricity had its prophets and exhibitions and wild promises. Now it powers everything quietly. The internet had its dot-com crash. What survived? Email, e-commerce, search—tools that actually work. AI will follow the same path. Not AGI prophecy. Not robot apocalypse. Just tools that solve specific problems. Exciting, useful, grounded.

And here's the beautiful part: what emerges after the crash is often more impactful than what was promised before it. The real revolution happens after the hype dies.

But don't get too comfortable. Every reload plants the seeds of the next simulation. The cycle continues. New technology, new prophets, new IKEA showrooms.

---

## Surfing the Simulacrum

Here's where The Matrix got it wrong. There's no red pill. There's no blue pill. Take both.

And here's where I have to be honest with you—because this essay's own logic demands it. I just spent several thousand words arguing that awareness doesn't break the spell. That cynical distance is how we tolerate participation. So how can I now tell you to "be aware" and "see through the simulation" as if that's a solution?

I can't. Not with a straight face. This advice lives inside the simulacrum too. I know that. You know that. The IKEA showroom has a section labeled "authentic living" and it's staged just like everything else.

But here's the difference between paralysis and surfing: you don't need to *escape* the simulation. You need to know which walls are load-bearing and which are painted backdrops. You can't exit IKEA, but you can stop buying furniture you don't need.

**Open source erodes narrator value.** Narrators control access, gatekeep knowledge, hide behind mystery. When the code is public, claims are testable. When models are open, anyone can verify, compete, improve. Llama didn't just challenge GPT—it broke the mystique. HuggingFace didn't just host models—it democratized capability. Open source doesn't destroy the simulation, but it makes the showroom walls thinner. You can see through them.

**Democracy of infrastructure.** Don't rent your capabilities from the narrators. Local compute, open models, community-owned tools. The more decentralized the infrastructure, the less leverage the simulation has over you. Build on foundations you can verify, not promises you have to trust.

**Build real value.** Use Value over Sign Value. Solve problems customers actually pay for—without VC subsidies propping up the illusion. When the reload comes, the things that actually work survive. The things that only exist as performance don't. This is the furniture test: would you still buy this if there were no showroom?

**Surf the glitches.** Train your eye for contradictions—valuations without customers, expertise without output, revenue that's recycled capital. When the story stops making sense, that's your signal. The collision isn't disaster for those paying attention. It's when the narrators lose their grip and the builders inherit the infrastructure.

Will following this advice make you free? No. You'll still live in the simulation. You'll still perform on LinkedIn. You'll still attend the conferences. But you'll build things that survive the reload—and that's the only freedom available inside a simulacrum.

You can't exit the showroom. But you can stop mistaking it for home.
